{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Conv2D, AveragePooling2D, Activation, GlobalAveragePooling2D, Lambda\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import Initializer\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset and dataset augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(xx_train, yy_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = xx_train[:40000]\n",
    "y_train = yy_train[:40000]\n",
    "\n",
    "x_validate = xx_train[40000:50000]\n",
    "y_validate = yy_train[40000:50000]\n",
    "\n",
    "x_train = x_train/255.0\n",
    "x_validate = x_validate/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_validate = to_categorical(y_validate, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''TRAINING DATA GENERATOR FOR DATA AUGMENTATION'''\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "train_datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(x,num_layers_per_block,growth_rate):\n",
    "    for i in range(num_layers_per_block//2):\n",
    "        x_ = BatchNormalization()(x)\n",
    "        x_ = Activation('relu')(x_)\n",
    "        x_ = Conv2D(number_filters,(3,3),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(0.0001))(x_)\n",
    "        x_ = Dropout(0.2)(x_)\n",
    "        x_ = BatchNormalization()(x_)\n",
    "        x_ = Activation('relu')(x_)\n",
    "        x = Concatenate()([x,x_])\n",
    "    return x \n",
    "\n",
    "def transition_layers(x,compression):\n",
    "    updated_num_filters = int(x.get_shape().as_list()[-1] * compression)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(updated_num_filters,(1,1),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(0.0001))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model parameters\n",
    "model_depth = 100\n",
    "num_dense_blocks = 3\n",
    "growth_rate = 12\n",
    "number_filters = 16\n",
    "compression = 0.5\n",
    "num_layers_per_block = (model_depth - 4) // num_dense_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's define the model\n",
    "inp = Input(x_train.shape[1:])\n",
    "x = Conv2D(number_filters,(1,1),padding='same',kernel_initializer='he_normal',kernel_regularizer=l2(0.0001))(inp)\n",
    "for i in range(num_dense_blocks):\n",
    "    x = dense_block(x,num_layers_per_block,growth_rate)\n",
    "    if (i != num_dense_blocks-1):\n",
    "        x = transition_layers(x,compression)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(10, activation='softmax',kernel_initializer='he_normal',kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "model = Model(inp, x)\n",
    "model.compile(Adam(), loss = 'categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Callbacks'''\n",
    "\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch, logs = {}):\n",
    "        training_losses.append(logs.get('loss'))\n",
    "        validation_losses.append(logs.get('val_loss'))\n",
    "        \n",
    "model_loss = LossHistory()\n",
    "\n",
    "checkpoint = ModelCheckpoint('model.h5', \n",
    "                             monitor = 'val_acc', \n",
    "                             verbose = 1,\n",
    "                             save_best_only = True,\n",
    "                             save_weights_only = False, \n",
    "                             mode = 'auto', \n",
    "                             period = 1\n",
    "                            )\n",
    "\n",
    "early_stop = EarlyStopping(monitor = 'val_acc', \n",
    "                           min_delta = 0, \n",
    "                           patience = 40, \n",
    "                           verbose = 0,\n",
    "                           mode = 'auto'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "init_lr = 0.0001\n",
    "dr = init_lr/epochs\n",
    "bs = 128\n",
    "\n",
    "lr = init_lr - (len(training_losses) * dr)\n",
    "model.optimizer = Adam(lr, decay = dr)\n",
    "\n",
    "'''model.fit(x_train, y_train, \n",
    "          batch_size = 32, \n",
    "          epochs = 150, \n",
    "          shuffle = True,\n",
    "          validation_data = (x_validate, y_validate),\n",
    "          callbacks=[earlyStopping]\n",
    "         )'''\n",
    "\n",
    "model.fit_generator(train_datagen.flow(x_train, y_train, batch_size = bs),\n",
    "                    validation_data = (x_validate, y_validate),\n",
    "                    steps_per_epoch = len(x_train) / bs, \n",
    "                    epochs = epochs,\n",
    "                    callbacks = [checkpoint, early_stop, model_loss]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Plot training and validation losses'''\n",
    "\n",
    "plt.plot(training_losses, label='Training Loss')\n",
    "plt.plot(validation_losses, label='Validation Loss')\n",
    "plt.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load best model and evaluate on test set'''\n",
    "\n",
    "best_model = load_model('model.h5')\n",
    "best_model.evaluate(x_test, y_test)\n",
    "\n",
    "evaluation = best_model.evaluate(x_test, y_test, \n",
    "                            batch_size = 512, \n",
    "                            verbose = 1\n",
    "                           )\n",
    "\n",
    "print('Loss: %.2f Accuracy: %.2f%%' % (evaluation[0], evaluation[1]*100.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
